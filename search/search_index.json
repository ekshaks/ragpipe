{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ragpipe","text":"<p>Ragpipe helps you build tools to get insights from your large document repositories quickly by building fast RAG pipelines.</p> <p>Ragpipe makes it easy to tweak components of your RAG pipeline so that you can iterate fast until you get desired accurate responses.</p> <p>Instead of the usual <code>chunk-embed-match-rank</code> flow, Ragpipe adopts a holistic, end-to-end view of the pipeline, consisting of:</p> <ul> <li>building the data model, </li> <li>choosing representations for document parts, </li> <li>specifying the correct bridges among representations, </li> <li>merging the retrieved docs across bridges,</li> <li>and using the retrieved docs to compute the query response</li> </ul> <p>The <code>represent-bridge-merge</code> pattern is very powerful and allows us to build all kinds of complex retrieval engines with <code>retrieve-rank-rerank</code> patterns.</p>"},{"location":"#key-ideas","title":"Key Ideas","text":"<p>Representations. Choose the query/document fields as well as how to represent each chosen query / document field to aid similarity/relevance computation (bridges) over the entire document repository. Representations can be text strings, dense/sparse vector embeddings or arbitrary data objects, and help bridge the gap between the query and the documents.</p> <p>Bridges. Choose a pair of query and document representation to bridge. A bridge serves as a relevance indicator: one of the several criteria for identifying the relevant documents for a query. In practice, several bridges together determine the degree to which a document is relevant to a query. Computing each bridge creates a unique ranked list of documents.</p> <p>Merges. Specify how to combine the bridges, e.g., combine multiple ranked list of documents into a single ranked list.</p> <p>Data Model. A hierarchical data structure that consists of all the (nested) documents. The data model is created from the original document files and is retained over the entire pipeline. We compute representations for arbitrary nested fields of the data, without flattening the data tree.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To query over a data repository, </p> <ul> <li>we compute the data model over the original data repository </li> <li>specify the document fields and the (multiple) representations to be computed for each field</li> <li>specify which representations to compute for query</li> <li>specify bridges: which pair of query and doc field representation should be matched</li> <li>merges: how to combine multiple bridges, sequentially or in parallel, to yield a curated ranked list of relevant documents.</li> <li>gen-response: how to generate response to the query using the relevant document list and a large language model.</li> </ul> <p>See example in <code>examples/quickstart</code>.</p> <ul> <li>read files to build a doc model with structure ...</li> <li>representations for <code>query.text</code> and <code>doc.title</code> fields <ul> <li><code>#dense</code> rep as vector embedding using <code>BAAI/bge-small-en-v1.5</code></li> <li><code>#sparse</code> rep using <code>bm25</code></li> </ul> </li> <li>specify two bridges <ul> <li><code>query.text#dense</code> and <code>doc.title#dense</code></li> <li><code>query.text#sparse</code> and <code>doc.title#sparse</code></li> </ul> </li> <li>combine the bridges in parallel using reciprocal rank fusion over the ranked list generated by each bridge.</li> </ul>"},{"location":"#faq","title":"FAQ","text":"<p>How / where do you chunk the long documents?</p> <p>Chunking happens during building the data model. Unlike conventional chunking, we do not create a flat \"list of text fields\" data model. Arbitrary parts of the document tree can be 'chunked' dynamically without losing the original document hierarchy. </p> <p>This makes it easy to explore different chunking strategies while retaining the unaffected parts of the downstream represent-bridge-merge pipeline.</p> <p>Which representations are supported?</p> <p>Ragpipe already includes a few popular dense and sparse vector encoders to get your pipeline started quickly. For example, BAAI/bge-small-en-v1.5, BM25, colbert-ir/colbertv2.0. The flexible configuration allows adding new external encoders by simply adding an <code>Encoder</code> class for the new encoder. Also, this allows us to keep the core of Ragpipe very lean.</p>"}]}